{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing sets\n",
    "path = (\"../datasets/data_100000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "def first_contact(dataframe):\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"dataframe shape is :\\t\")\n",
    "    print(dataframe.shape)\n",
    "    print(\"data_columns are : \\n\")\n",
    "    print(dataframe.columns)\n",
    "    print(dataframe.dtypes)\n",
    "    print(\"\\n Number of values missing in each columns:\\n\")\n",
    "    print(dataframe.isnull().sum())\n",
    "    print(\"-----------------------------------------\")\n",
    "    return\n",
    "\n",
    "def drop_too_much(dataframe,val=0.8):\n",
    "    \"\"\"return a list of column where the missing value % is sup to val\"\"\"\n",
    "    if val >1:\n",
    "        raise ValueError(\"val should be inf to 1\")\n",
    "    threshold = len(dataframe)*val \n",
    "    to_drop =[i for i,x in dataframe.isnull().sum().iteritems() if x>=threshold ]\n",
    "    return to_drop\n",
    "    \n",
    "def searching_possible_transformable_variables(dataframe,v=False):\n",
    "    for colname,coldata in dataframe.iteritems():\n",
    "        if coldata.nunique()<= 15 and dataframe[colname].dtypes==object:\n",
    "            print(\"For the column \"+colname)\n",
    "            print(\"The number of unique values is \" +str(dataframe[colname].nunique()))\n",
    "            print(dataframe[colname].value_counts())\n",
    "            print(dataframe[colname].dtypes)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "NY_dataset = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Reminder TODO :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - removing col with more then 50% missing values\n",
    "> - remove the \"location\" column.  It's redundant\n",
    "> - converting the \"zipcode\" column to int\n",
    "> - the values in columns \"vehicle_type_code\"1 and 2 can  be consolidated\n",
    "> - Slice  crash date into month/day/year\n",
    "> - Slice crash time into  hour/min\n",
    "> - transform the values of the column \"borough\" into binaries\n",
    "> - remove absurd values if there is (now, none were found)\n",
    "> - maybe divide the values of NY_dataset[\"contributing_factor_vehicle_1\"].value_counts() into more general subset?\n",
    "> - We have no duplicates\n",
    "> - We dont need need  to normalize any data\n",
    "> - We may need to resample some classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working on a copy\n",
    "NY_copy = NY_dataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- removing col with more then 30% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = drop_too_much(NY_copy,val=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['borough',\n",
       " 'zip_code',\n",
       " 'off_street_name',\n",
       " 'cross_street_name',\n",
       " 'contributing_factor_vehicle_3',\n",
       " 'contributing_factor_vehicle_4',\n",
       " 'contributing_factor_vehicle_5',\n",
       " 'vehicle_type_code_3',\n",
       " 'vehicle_type_code_4',\n",
       " 'vehicle_type_code_5']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "NY_copy.drop(cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- remove the \"location\" column.  It's redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "NY_copy.drop(\"location\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- converting the \"zipcode\" column to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['crash_date', 'crash_time', 'latitude', 'longitude', 'on_street_name',\n",
       "       'number_of_persons_injured', 'number_of_persons_killed',\n",
       "       'number_of_pedestrians_injured', 'number_of_pedestrians_killed',\n",
       "       'number_of_cyclist_injured', 'number_of_cyclist_killed',\n",
       "       'number_of_motorist_injured', 'number_of_motorist_killed',\n",
       "       'contributing_factor_vehicle_1', 'contributing_factor_vehicle_2',\n",
       "       'collision_id', 'vehicle_type_code1', 'vehicle_type_code2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NY_copy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Most of the times when zip is  nan,  borough is not known either"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "becode",
   "language": "python",
   "name": "becode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
